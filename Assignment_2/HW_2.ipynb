{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "## Social Media Analytics\n",
    "\n",
    "Clarissa Franklin, Kyle Katzen, Paige McKenzie, Meyappan Subbaiah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task A.\n",
    "We brainstormed a list of major political topics that we thought would be relevant from 1789-2018. Our list included eight topics: war, voting, equality, slavery, taxes, economy, transportation, and international relations. We believe that these are the major topics that will appear, but also expected approximately two additional topics to appear in the speeches that we did not include. For this reason, we chose to model 10 topics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task B. \n",
    "#### topic modelling with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clari\\Anaconda2\\envs\\py36\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import nltk\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import gensim\n",
    "import sklearn\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "      <th>text_joined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1789</td>\n",
       "      <td>04</td>\n",
       "      <td>30</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>[fellow, citizen, senat, vicissitud, incid, li...</td>\n",
       "      <td>fellow citizen senat hous repres among vicissi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789</td>\n",
       "      <td>10</td>\n",
       "      <td>03</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>[wherea, acknowledg, provid, almighti, god, ob...</td>\n",
       "      <td>wherea duti nation acknowledg provid almighti ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790</td>\n",
       "      <td>01</td>\n",
       "      <td>08</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>[fellow, citizen, senat, embrac, opportun, con...</td>\n",
       "      <td>fellow citizen senat hous repres embrac great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1790</td>\n",
       "      <td>12</td>\n",
       "      <td>08</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>[fellow, citizen, senat, meet, feel, much, abl...</td>\n",
       "      <td>fellow citizen senat hous repres meet feel muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1790</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>[presid, mouth, written, speech, sign, hand, s...</td>\n",
       "      <td>presid unit state mouth written speech sign ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year month day            speaker  \\\n",
       "0  1789    04  30  George Washington   \n",
       "1  1789    10  03  George Washington   \n",
       "2  1790    01  08  George Washington   \n",
       "3  1790    12  08  George Washington   \n",
       "4  1790    12  29  George Washington   \n",
       "\n",
       "                                                text  \\\n",
       "0  [fellow, citizen, senat, vicissitud, incid, li...   \n",
       "1  [wherea, acknowledg, provid, almighti, god, ob...   \n",
       "2  [fellow, citizen, senat, embrac, opportun, con...   \n",
       "3  [fellow, citizen, senat, meet, feel, much, abl...   \n",
       "4  [presid, mouth, written, speech, sign, hand, s...   \n",
       "\n",
       "                                         text_joined  \n",
       "0  fellow citizen senat hous repres among vicissi...  \n",
       "1  wherea duti nation acknowledg provid almighti ...  \n",
       "2  fellow citizen senat hous repres embrac great ...  \n",
       "3  fellow citizen senat hous repres meet feel muc...  \n",
       "4  presid unit state mouth written speech sign ha...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "        \n",
    "df = pd.DataFrame(columns=['year', 'month', 'day', 'speaker', 'text'])\n",
    "\n",
    "for filename in os.listdir(\"data\"):\n",
    "    with open(os.path.join(\"data\", filename), 'r') as book:\n",
    "        s = pd.Series(filename.split(' ',1)[0].split('-')+[filename.split(' ',1)[1][:-4], book.read()], \n",
    "                      index=['year', 'month', 'day', 'speaker', 'text'])\n",
    "        df=df.append(s, ignore_index=True)\n",
    "#test with small\n",
    "df=df[0:5]\n",
    "\n",
    "df['text']=df['text'].apply(lambda x: re.sub(\"[^\\w\\s'+]\",'', x)) \n",
    "\n",
    "\n",
    "\n",
    "df['text']=df['text'].apply(lambda x: [stemmer.stem(lemmatizer.lemmatize(item.lower())) for item in x.split() if item.lower() not in stop])\n",
    "\n",
    "tf_vect=TfidfVectorizer(max_df=0.75, min_df=0.1)\n",
    "\n",
    "df['text_joined']=df['text'].str.join(sep=\" \")\n",
    "x = tf_vect.fit_transform(df['text_joined']).todense()\n",
    "tf_words=tf_vect.get_feature_names()\n",
    "\n",
    "real_words=[]\n",
    "for word in tf_words:\n",
    "    first=word.split()[0]\n",
    "    if first.isalpha():\n",
    "        real_words+=[word]\n",
    "real_words\n",
    "\n",
    "#get frequency of words whole corpus\n",
    "#init=[]\n",
    "#corp=[i+init for i in df['text']][0]\n",
    "#freq_dist = nltk.FreqDist(corp)\n",
    "\n",
    "#also remove words that do not meet tf-idf thresholds (appear in nearly all documents, or are obscure words that do not appear in more than 10% of documents)\n",
    "df['text'] = df['text'].apply(lambda x: [ word for word in x if word in real_words])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(1011 unique tokens: ['fellow', 'citizen', 'senat', 'vicissitud', 'incid']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora as cp\n",
    "#create the term dictionary of our corpus, where every unique term is assigned an index\n",
    "dictionary=cp.Dictionary(df['text'].values)\n",
    "\n",
    "len(dictionary)\n",
    "print(dictionary)\n",
    "#convert list of documets into document term matrix using the dictionary\n",
    "\n",
    "doc_term_matrix=[dictionary.doc2bow(doc) for doc in df['text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>words_and_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001*\"measur\" + 0.001*\"part\" + 0.001*\"citizen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001*\"land\" + 0.001*\"care\" + 0.001*\"futur\" + ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.007*\"one\" + 0.007*\"ought\" + 0.007*\"execut\" +...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.001*\"part\" + 0.001*\"measur\" + 0.001*\"made\" +...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.001*\"land\" + 0.001*\"measur\" + 0.001*\"citizen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic                                  words_and_weights\n",
       "0      0  0.001*\"measur\" + 0.001*\"part\" + 0.001*\"citizen...\n",
       "1      1  0.001*\"land\" + 0.001*\"care\" + 0.001*\"futur\" + ...\n",
       "2      2  0.007*\"one\" + 0.007*\"ought\" + 0.007*\"execut\" +...\n",
       "3      3  0.001*\"part\" + 0.001*\"measur\" + 0.001*\"made\" +...\n",
       "4      4  0.001*\"land\" + 0.001*\"measur\" + 0.001*\"citizen..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=10, id2word = dictionary, passes=50)\n",
    "\n",
    "#print the topics\n",
    "topics=pd.DataFrame(ldamodel.print_topics(num_topics=10, num_words=6), columns=['topic', 'words_and_weights'])\n",
    "topics.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
